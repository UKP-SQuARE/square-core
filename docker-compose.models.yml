# only for dev work

version: "3.3"

services:
  traefik:
    image: traefik:v2.8.7
    #container_name: traefik
    command:
      - --api.insecure=true
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --entrypoints.web.address=:80
      - --accesslog=true
      - --accesslog.format=json
      - --accesslog.filepath=/var/log/traefik/access.log.json
      # Enable https port 443
      - --entrypoints.websecure.address=:443
      - --certificatesresolvers.le.acme.tlschallenge=true
      # Uncomment staging certs for testing
      - --certificatesresolvers.le.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory
      - --certificatesresolvers.le.acme.email=sachdeva@ukp.informatik.tu-darmstadt.de
      - --certificatesresolvers.le.acme.storage=/certificates/acme.json
      # Enable dashboard and logging
      - --api.dashboard=true
      - --log.level=DEBUG
    ports:
      - "8989:80"  # http port
      - "8443:443"  # https port
      - "8080:8080"  # web UI port
    labels:
      - "traefik.enable=true"
      # Global redirect to https
      - "traefik.http.routers.http-catchall.rule=hostregexp(`{host:.+}`)"
      - "traefik.http.routers.http-catchall.entrypoints=web"
      - "traefik.http.routers.http-catchall.middlewares=https-redirect"

      # Middleware redirect from HTTP to HTTPS
      - "traefik.http.middlewares.https-redirect.redirectscheme.scheme=https"
      - "traefik.http.middlewares.https-redirect.redirectscheme.port=8443"
      - "traefik.http.middlewares.https-redirect.redirectscheme.permanent=true"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # mount volume to store certificates
      - traefik-public-certificates:/certificates

  rabbit:
    hostname: rabbit
    image: rabbitmq:3.9.14-management
    ports:
      - 5672:5672
      - 15672:15672
    #    env_file:
    #      - ./management_server/.env
    env_file:
      - ./model-manager/.env
    #    volumes:
    #      - ./management_server/rabbitmq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    #      - ./management_server/rabbitmq/definitions.json:/etc/rabbitmq/definitions.json

  redis:
    hostname: redis
    image: redis:latest
    ports:
      - '6379:6379'
    #    env_file:
    #      - .env
    env_file:
      - .env
    command: [ "redis-server", "--requirepass ${REDIS_PASSWORD}" ]

  mongo:
    hostname: mongo
    image: mongo:5.0.4
    restart: always
    volumes:
      - mongo-data:/data/db
    ports:
      - 27017:27017
    env_file:
      - ./model-manager/.env

  maintaining_worker:
    #    image: ukpsquare/square-model-management-v2:latest
    #    build: ./management_server
    build:
      context: ./model-manager
      dockerfile: Dockerfile
    #iner_name: maintaining_worker
    command: celery -A tasks worker --loglevel=info
    volumes:
      - ./:/usr/src/app
      - /var/run/docker.sock:/var/run/docker.sock
    env_file:
      - ./model-manager/.env
    environment:
      - DOCKER_HOST_URL=https://172.17.0.1:8443
      - MODEL_API_IMAGE=ukpsquare/model-inference
      - MONGO_INITDB_ROOT_USERNAME=root
      - VERIFY_SSL=0
      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
      - REALM=square
      - CLIENT_ID=models
      - CONFIG_VOLUME=square-core_model_configs
    links:
      - rabbit
      - redis
    depends_on:
      - maintaining
      - rabbit
      - redis

  maintaining:
    #    image: ukpsquare/square-model-management-v2:latest
    command: uvicorn model_manager.main:app --host 0.0.0.0 --port 9001 --log-config logging.conf
    #iner_name: maintaining
    build:
      context: ./model-manager
      dockerfile: Dockerfile
    ports:
      - 9001:9001
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    links:
      - mongo
    depends_on:
      - mongo
    env_file:
      - ./model-manager/.env
    environment:
      - DOCKER_HOST_URL=https://172.17.0.1:8443
      - MODEL_API_IMAGE=ukpsquare/model-inference
      - VERIFY_SSL=0
      - WEB_CONCURRENCY=1
      - ONNX_VOLUME=model-inference_onnx-models
      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
      - REALM=square
      - CLIENT_ID=models
      - CONFIG_PATH=/model_configs
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.maintaining.rule=PathPrefix(`/api/models`)"
      - "traefik.http.routers.maintaining.entrypoints=websecure"
      - "traefik.http.routers.maintaining.tls=true"
      - "traefik.http.routers.maintaining.tls.certresolver=le"
      - "traefik.http.routers.maintaining.middlewares=maintaining-stripprefix,maintaining-addprefix"
      - "traefik.http.middlewares.maintaining-stripprefix.stripPrefixRegex.regex=/api/[a-zA-Z0-9_-]+"
      - "traefik.http.middlewares.maintaining-addprefix.addPrefix.prefix=/api"

##################################################################
# --------- Example config for transformer model server ---------#
##################################################################
  main_model:
#    image: ukpsquare/model-inference-transformer:latest
    build:
      context: ./model-inference
      dockerfile: Dockerfile
      args:
        - MODEL_TYPE=transformer
        - TEST_SETUP=transformer
    #container_name: main_model
    command: uvicorn model_inference.main:app --host 0.0.0.0 --port 8000 --reload
    env_file:
      - ./model-inference/model_configurations/.env.dpr
      - ./model-inference/.env
    environment:
      - WEB_CONCURRENCY=1
      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
      - QUEUE=facebook-dpr-question_encoder-single-nq-base
      - CONFIG_PATH=/model_configs
#      - TEST=1   # for testing model config
    volumes:
      - ./.cache/:/etc/huggingface/.cache/
      - model_configs:/model_configs
#      - onnx-models:/onnx_models
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.model-dpr.rule=PathPrefix(`/api/main`)"
      - "traefik.http.routers.model-dpr.entrypoints=websecure"
      - "traefik.http.routers.model-dpr.tls=true"
      - "traefik.http.routers.model-dpr.tls.certresolver=le"
      - "traefik.http.routers.model-dpr.middlewares=model-dpr-stripprefix,model-dpr-addprefix"
      - "traefik.http.middlewares.model-dpr-stripprefix.stripprefix.prefixes=/api/main"
      - "traefik.http.middlewares.model-dpr-addprefix.addPrefix.prefix=/api"

  dpr_worker:
    build:
      context: ./model-inference
      dockerfile: Dockerfile
      args:
        - MODEL_TYPE=transformer
        - TEST_SETUP=transformer
    command: celery -A tasks worker -Q facebook-dpr-question_encoder-single-nq-base --loglevel=info
    volumes:
      - ./:/usr/src/app
      - /var/run/docker.sock:/var/run/docker.sock
      - model_configs:/model_configs
    env_file:
      - ./model-inference/model_configurations/.env.dpr
      - ./model-inference/.env
    environment:
      - DOCKER_HOST_URL=https://172.17.0.1:8443
      - VERIFY_SSL=0
      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
      - REALM=square
      - CLIENT_ID=models
      - QUEUE=facebook-dpr-question_encoder-single-nq-base
      - CONFIG_PATH=/model_configs
    links:
      - rabbit
      - redis
    depends_on:
      - maintaining
      - rabbit
      - redis

  metaqa_worker:
    build:
      context: ./model-inference
      dockerfile: Dockerfile
      args:
        - MODEL_TYPE=transformer
        - TEST_SETUP=transformer
    command: celery -A tasks worker -Q metaqa --loglevel=info
    volumes:
      - ./:/usr/src/app
      - /var/run/docker.sock:/var/run/docker.sock
      - model_configs:/model_configs
    env_file:
      - ./model-inference/model_configurations/.env.metaqa
      - ./model-inference/.env
    environment:
      - DOCKER_HOST_URL=https://172.17.0.1:8443
      - VERIFY_SSL=0
      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
      - REALM=square
      - CLIENT_ID=models
      - QUEUE=metaqa
      - CONFIG_PATH=/model_configs
    links:
      - rabbit
      - redis
    depends_on:
      - maintaining
      - rabbit
      - redis


  #  tweac_worker:
#    build:
#      context: ./modeinference
#      dockerfile: ./dockerfiles/transformer/Dockerfile
#    container_name: tweac_worker
#    command: celery -A tasks worker -Q tweac --loglevel=info --concurrency=1
#    volumes:
#      - ./:/usr/src/app
#      - /var/run/docker.sock:/var/run/docker.sock
#      - model_configs:/model_configs
#    env_file:
#      - inference_api/model_configurations/.env.tweac
#      - .env
#    environment:
#      - DOCKER_HOST_URL=https://172.17.0.1:8443
#      - VERIFY_SSL=0
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#      - REALM=square
#      - CLIENT_ID=models
#      - QUEUE=tweac
#      - CONFIG_PATH=/model_configs
#    links:
#      - rabbit
#      - redis
#    depends_on:
#      - maintaining
#      - rabbit
#      - redis

#  distilbert_sentence_transformer:
#    build:
#      context: ./model_inference
#      dockerfile: ./dockerfiles/sentence_transformer/Dockerfile
#    command: celery -A tasks worker -Q distilbert --loglevel=info
#    volumes:
#      - ./:/usr/src/app
#      - /var/run/docker.sock:/var/run/docker.sock
#      - model_configs:/model_configs
#    env_file:
#      - ./inference_api/model_configurations/.env.distilbert_sentence_transformer
#      - .env
#    environment:
#      - DOCKER_HOST_URL=https://172.17.0.1:8443
#      - VERIFY_SSL=0
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#      - REALM=square
#      - CLIENT_ID=models
#      - QUEUE=distilbert
#      - CONFIG_PATH=/model_configs
#    links:
#      - rabbit
#      - redis
#    depends_on:
#      - maintaining
#      - rabbit
#      - redis

  bert_worker:
    build:
      context: ./model-inference
      dockerfile: Dockerfile
      args:
        - MODEL_TYPE=transformer
        - TEST_SETUP=transformer
    #container_name: bert_worker
    command: celery -A tasks worker -Q bert-base-uncased --loglevel=info --concurrency=2
    volumes:
      - ./:/usr/src/app
      - /var/run/docker.sock:/var/run/docker.sock
      - model_configs:/model_configs
    env_file:
      - ./model-inference/model_configurations/.env.bert_adapter
      - ./model-inference/.env
    environment:
      - DOCKER_HOST_URL=https://172.17.0.1:8443
      - VERIFY_SSL=0
      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
      - REALM=square
      - CLIENT_ID=models
      - QUEUE=bert-base-uncased
      - CONFIG_PATH=/model_configs
    links:
      - rabbit
      - redis
    depends_on:
      - maintaining
      - rabbit
      - redis

#  roberta_worker:
#    build:
#      context: ./model-inference
#      dockerfile: ./dockerfiles/transformer/Dockerfile
#    container_name: roberta_worker
#    command: celery -A tasks worker -Q roberta-base --loglevel=info --concurrency=2
#    volumes:
#      - ./:/usr/src/app
#      - /var/run/docker.sock:/var/run/docker.sock
#      - model_configs:/model_configs
#    env_file:
#      - model_configurations/.env.roberta_adapter
#      - .env
#    environment:
#      - DOCKER_HOST_URL=https://172.17.0.1:8443
#      - VERIFY_SSL=0
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#      - REALM=square
#      - CLIENT_ID=models
#      - QUEUE=roberta-base
#      - CONFIG_PATH=/model_configs
#    links:
#      - rabbit
#      - redis
#    depends_on:
#      - maintaining
#      - rabbit
#      - redis

#  qagnn_worker:
#    build:
#      context: ./model_inference
#      dockerfile: ./dockerfiles/graph_transformer/Dockerfile
#    command: celery -A tasks worker -Q qagnn --loglevel=info
#    volumes:
#      - ./:/usr/src/app
#      - /var/run/docker.sock:/var/run/docker.sock
#      - model_configs:/model_configs
#      - models:/models
#    env_file:
#      - ./inference_server/.env.qagnn
#      - inference_server/.env
#    environment:
#      - DOCKER_HOST_URL=https://172.17.0.1:8443
#      - VERIFY_SSL=0
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#      - REALM=square
#      - CLIENT_ID=models
#      - QUEUE=qagnn
#      - CONFIG_PATH=/model_configs
#    links:
#      - rabbit
#      - redis
#    depends_on:
#      - maintaining
#      - rabbit
#      - redis

#  bart_worker:
#    build:
#      context: ./model_inference
#      dockerfile: dockerfiles/transformer/Dockerfile
#    command: celery -A tasks worker -Q bart-base --loglevel=info
#    volumes:
#      - ./:/usr/src/app
#      - /var/run/docker.sock:/var/run/docker.sock
#      - model_configs:/model_configs
#    env_file:
#      - ./inference_server/.env.bart_adapter
#      - inference_server/.env
#    environment:
#      - DOCKER_HOST_URL=https://172.17.0.1:8443
#      - VERIFY_SSL=0
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#      - REALM=square
#      - CLIENT_ID=models
#      - QUEUE=bart-base
#      - CONFIG_PATH=/model_configs
#    links:
#      - rabbit
#      - redis
#    depends_on:
#      - maintaining
#      - rabbit
#      - redis

#  # --------- Example config for abstractive QA adapter model server ---------
#  model_bart_base_adapter:
#    #    image: ukpsquare/square-model-api-v1:latest
#    build: ./model_inference
#    env_file:
#      - ./inference_server/.env.bart_adapter
#    environment:
#      - WEB_CONCURRENCY=1
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#    volumes:
#      - ./.cache/:/etc/huggingface/.cache/
#    labels:
#      - "traefik.enable=true"
#      - "traefik.http.routers.model-bart-base-adapter.rule=PathPrefix(`/api/facebook-bart-base`)"
#      - "traefik.http.routers.model-bart-base-adapter.entrypoints=websecure"
#      - "traefik.http.routers.model-bart-base-adapter.tls=true"
#      - "traefik.http.routers.model-bart-base-adapter.tls.certresolver=le"
#      - "traefik.http.routers.model-bart-base-adapter.middlewares=model-bart-base-adapter-stripprefix,model-bart-base-adapter-addprefix"
#      - "traefik.http.middlewares.model-bart-base-adapter-stripprefix.stripprefix.prefixes=/api/facebook-bart-base"
#      - "traefik.http.middlewares.model-bart-base-adapter-addprefix.addPrefix.prefix=/api"

#    env_file:
#      - management_server/.env

#  mongo-express:
#    image: mongo-express:latest
#    restart: always
#    env_file:
#      - ./model-manager/.env
#    ports:
#      - 8081:8081

###########################################################
# --------- Example config for onnx model server ---------#
###########################################################
#  bert_onnx:
##    image: ukpsquare/square-model-api-v1:latest
#    build:
#      context: ./inference_api
#      dockerfile: ./dockerfiles/onnx/Dockerfile
#    env_file:
#      - ./inference_api/model_configs/.env.bert_onnx
#      - .env
#    environment:
#      - WEB_CONCURRENCY=1
#      - KEYCLOAK_BASE_URL=https://square.ukp.informatik.tu-darmstadt.de
#    volumes:
#      - ./.cache/:/etc/onnx/.cache/
#      - onnx-models:/onnx_models
#      - model_configs:/model_configs
#    labels:
#      - "traefik.enable=true"
#      - "traefik.http.routers.model-bert-onnx.rule=PathPrefix(`/api/bert-onnx`)"
#      - "traefik.http.routers.model-bert-onnx.entrypoints=websecure"
#      - "traefik.http.routers.model-bert-onnx.tls=true"
#      - "traefik.http.routers.model-bert-onnx.tls.certresolver=le"
#      - "traefik.http.routers.model-bert-onnx.middlewares=model-bert-onnx-stripprefix,model-bert-onnx-addprefix"
#      - "traefik.http.middlewares.model-bert-onnx-stripprefix.stripprefix.prefixes=/api/bert-onnx"
#      - "traefik.http.middlewares.model-bert-onnx-addprefix.addPrefix.prefix=/api"

#  bert_onnx_worker:
#    build:
#      context: ./inference_api
#      dockerfile: ./dockerfiles/onnx/Dockerfile
#    command: celery -A tasks worker -Q bert_onnx --loglevel=info
#    volumes:
#      - ./:/usr/src/app
#      - /var/run/docker.sock:/var/run/docker.sock
#      - model_configs:/model_configs
#      - onnx-models:/onnx_models
#    env_file:
#      - ./inference_api/model_configs/.env.bert_onnx
#      - .env
#    environment:
#      - DOCKER_HOST_URL=https://172.17.0.1:8443
#      - VERIFY_SSL=0
#      - KEYCLOAK_BASE_URL=https://square.ukp-lab.de
#      - REALM=square
#      - CLIENT_ID=models
#      - QUEUE=bert_onnx
#      - CONFIG_PATH=/model_configs
#    links:
#      - rabbit
#      - redis
#    depends_on:
#      - maintaining
#      - rabbit
#      - redis

volumes:
  traefik-public-certificates:

  mongo-data:
    driver: local

#  square-redis-data:
#    driver: local

  # onnx-model folder on the vm
  onnx-models:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /home/rachneet/onnx_models

  model_storage:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /home/rachneet/projects/qagnn/data/

  model_configs:
    driver: local