import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import softmax
from torch_scatter import scatter

from .layers import *
from .modeling_encoder import TextEncoder


###############################################################################
############################### GNN architecture ##############################
###############################################################################


class QAGNN_Message_Passing(nn.Module):
    def __init__(
        self,
        args,
        k,
        n_ntype,
        n_etype,
        input_size,
        hidden_size,
        output_size,
        dropout=0.1,
    ):
        super().__init__()
        assert input_size == output_size
        self.args = args
        self.n_ntype = n_ntype
        self.n_etype = n_etype

        assert input_size == hidden_size
        self.hidden_size = hidden_size

        self.emb_node_type = nn.Linear(self.n_ntype, hidden_size // 2)

        self.basis_f = "sin"  # ['id', 'linact', 'sin', 'none']
        if self.basis_f in ["id"]:
            self.emb_score = nn.Linear(1, hidden_size // 2)
        elif self.basis_f in ["linact"]:
            self.B_lin = nn.Linear(1, hidden_size // 2)
            self.emb_score = nn.Linear(hidden_size // 2, hidden_size // 2)
        elif self.basis_f in ["sin"]:
            self.emb_score = nn.Linear(hidden_size // 2, hidden_size // 2)

        self.edge_encoder = torch.nn.Sequential(
            torch.nn.Linear(n_etype + 1 + n_ntype * 2, hidden_size),
            torch.nn.BatchNorm1d(hidden_size),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_size, hidden_size),
        )

        self.k = k
        self.gnn_layers = nn.ModuleList(
            [GATConvE(args, hidden_size, n_ntype, n_etype, self.edge_encoder) for _ in range(k)]
        )

        self.Vh = nn.Linear(input_size, output_size)
        self.Vx = nn.Linear(hidden_size, output_size)

        self.activation = GELU()
        self.dropout = nn.Dropout(dropout)
        self.dropout_rate = dropout

    def mp_helper(self, _X, edge_index, edge_type, _node_type, _node_feature_extra):
        for _ in range(self.k):
            _X = self.gnn_layers[_](_X, edge_index, edge_type, _node_type, _node_feature_extra)
            _X = self.activation(_X)
            _X = F.dropout(_X, self.dropout_rate, training=self.training)
        return _X

    def forward(self, H, A, node_type, node_score):
        """
        H: tensor of shape (batch_size, n_node, d_node)
            node features from the previous layer
        A: (edge_index, edge_type)
        node_type: long tensor of shape (batch_size, n_node)
            0 == question entity; 1 == answer choice entity; 2 == other node; 3 == context node
        node_score: tensor of shape (batch_size, n_node, 1)
        """
        _batch_size, _n_nodes = node_type.size()

        # Embed type
        T = make_one_hot(node_type.view(-1).contiguous(), self.n_ntype).view(_batch_size, _n_nodes, self.n_ntype)
        node_type_emb = self.activation(self.emb_node_type(T))

        # Embed score
        if self.basis_f == "sin":
            js = torch.arange(self.hidden_size // 2).unsqueeze(0).unsqueeze(0).float().to(node_type.device)
            js = torch.pow(1.1, js)
            B = torch.sin(js * node_score)
            node_score_emb = self.activation(self.emb_score(B))
        elif self.basis_f == "id":
            B = node_score
            node_score_emb = self.activation(self.emb_score(B))
        elif self.basis_f == "linact":
            B = self.activation(self.B_lin(node_score))
            node_score_emb = self.activation(self.emb_score(B))

        X = H
        edge_index, edge_type = A
        _X = X.view(-1, X.size(2)).contiguous()
        _node_type = node_type.view(-1).contiguous()
        _node_feature_extra = (
            torch.cat([node_type_emb, node_score_emb], dim=2).view(_node_type.size(0), -1).contiguous()
        )

        _X = self.mp_helper(_X, edge_index, edge_type, _node_type, _node_feature_extra)

        X = _X.view(node_type.size(0), node_type.size(1), -1)

        output = self.activation(self.Vh(H) + self.Vx(X))
        output = self.dropout(output)

        return output


class QAGNN(nn.Module):
    def __init__(
        self,
        args,
        k,
        n_ntype,
        n_etype,
        sent_dim,
        n_concept,
        concept_dim,
        concept_in_dim,
        n_attention_head,
        fc_dim,
        n_fc_layer,
        p_emb,
        p_gnn,
        p_fc,
        pretrained_concept_emb=None,
        freeze_ent_emb=True,
        init_range=0.02,
    ):
        super().__init__()
        self.init_range = init_range

        self.concept_emb = CustomizedEmbedding(
            concept_num=n_concept,
            concept_out_dim=concept_dim,
            use_contextualized=False,
            concept_in_dim=concept_in_dim,
            pretrained_concept_emb=pretrained_concept_emb,
            freeze_ent_emb=freeze_ent_emb,
        )
        self.svec2nvec = nn.Linear(sent_dim, concept_dim)

        self.concept_dim = concept_dim

        self.activation = GELU()

        self.gnn = QAGNN_Message_Passing(
            args,
            k=k,
            n_ntype=n_ntype,
            n_etype=n_etype,
            input_size=concept_dim,
            hidden_size=concept_dim,
            output_size=concept_dim,
            dropout=p_gnn,
        )

        self.pooler = MultiheadAttPoolLayer(n_attention_head, sent_dim, concept_dim)

        self.fc = MLP(
            concept_dim + sent_dim + concept_dim,
            fc_dim,
            1,
            n_fc_layer,
            p_fc,
            layer_norm=True,
        )

        self.dropout_e = nn.Dropout(p_emb)
        self.dropout_fc = nn.Dropout(p_fc)

        if init_range > 0:
            self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, (nn.Linear, nn.Embedding)):
            module.weight.data.normal_(mean=0.0, std=self.init_range)
            if hasattr(module, "bias") and module.bias is not None:
                module.bias.data.zero_()
        elif isinstance(module, nn.LayerNorm):
            module.bias.data.zero_()
            module.weight.data.fill_(1.0)

    def forward(
        self,
        sent_vecs,
        concept_ids,
        node_type_ids,
        node_scores,
        adj_lengths,
        adj,
        emb_data=None,
        cache_output=False,
    ):
        """
        sent_vecs: (batch_size, dim_sent)
        concept_ids: (batch_size, n_node)
        adj: edge_index, edge_type
        adj_lengths: (batch_size,)
        node_type_ids: (batch_size, n_node)
            0 == question entity; 1 == answer choice entity; 2 == other node; 3 == context node
        node_scores: (batch_size, n_node, 1)

        returns: (batch_size, 1)
        """
        gnn_input0 = self.activation(self.svec2nvec(sent_vecs)).unsqueeze(1)
        gnn_input1 = self.concept_emb(concept_ids[:, 1:] - 1, emb_data)
        gnn_input1 = gnn_input1.to(node_type_ids.device)
        gnn_input = self.dropout_e(torch.cat([gnn_input0, gnn_input1], dim=1))

        _mask = (torch.arange(node_scores.size(1), device=node_scores.device) < adj_lengths.unsqueeze(1)).float()
        node_scores = -node_scores
        node_scores = node_scores - node_scores[:, 0:1, :]
        node_scores = node_scores.squeeze(2)
        node_scores = node_scores * _mask
        mean_norm = (torch.abs(node_scores)).sum(dim=1) / adj_lengths
        node_scores = node_scores / (mean_norm.unsqueeze(1) + 1e-05)
        node_scores = node_scores.unsqueeze(2)

        gnn_output = self.gnn(gnn_input, adj, node_type_ids, node_scores)
        Z_vecs = gnn_output[:, 0]

        mask = torch.arange(node_type_ids.size(1), device=node_type_ids.device) >= adj_lengths.unsqueeze(1)

        mask = mask | (node_type_ids == 3)  # pool over all KG nodes
        mask[mask.all(1), 0] = 0  # a temporary solution to avoid zero node

        sent_vecs_for_pooler = sent_vecs
        # print(sent_vecs_for_pooler.size())
        graph_vecs, pool_attn = self.pooler(sent_vecs_for_pooler, gnn_output, mask)

        if cache_output:
            self.concept_ids = concept_ids
            self.adj = adj
            self.pool_attn = pool_attn

        concat = self.dropout_fc(torch.cat((graph_vecs, sent_vecs, Z_vecs), 1))
        logits = self.fc(concat)
        return logits, pool_attn


class LM_QAGNN(nn.Module):
    def __init__(
        self,
        args,
        model_name,
        k,
        n_ntype,
        n_etype,
        n_concept,
        concept_dim,
        concept_in_dim,
        n_attention_head,
        fc_dim,
        n_fc_layer,
        p_emb,
        p_gnn,
        p_fc,
        pretrained_concept_emb=None,
        freeze_ent_emb=True,
        init_range=0.0,
        encoder_config={},
    ):
        super().__init__()
        self.encoder = TextEncoder(model_name, **encoder_config)
        self.decoder = QAGNN(
            args,
            k,
            n_ntype,
            n_etype,
            self.encoder.sent_dim,
            n_concept,
            concept_dim,
            concept_in_dim,
            n_attention_head,
            fc_dim,
            n_fc_layer,
            p_emb,
            p_gnn,
            p_fc,
            pretrained_concept_emb=pretrained_concept_emb,
            freeze_ent_emb=freeze_ent_emb,
            init_range=init_range,
        )

    def forward(self, *inputs, layer_id=-1, cache_output=False, detail=False):
        """
        sent_vecs: (batch_size, num_choice, d_sent)    -> (batch_size * num_choice, d_sent)
        concept_ids: (batch_size, num_choice, n_node)  -> (batch_size * num_choice, n_node)
        node_type_ids: (batch_size, num_choice, n_node) -> (batch_size * num_choice, n_node)
        adj_lengths: (batch_size, num_choice)          -> (batch_size * num_choice, )
        adj -> edge_index, edge_type
        edge_index: list of (batch_size, num_choice) -> list of (batch_size * num_choice, );
                                                        each entry is torch.tensor(2, E(variable))
                                                         -> (2, total E)
        edge_type:  list of (batch_size, num_choice) -> list of (batch_size * num_choice, );
                                                        each entry is torch.tensor(E(variable), )
                                                         -> (total E, )
        returns: (batch_size, 1)
        """

        bs, nc = inputs[0].size(0), inputs[0].size(1)

        # Here, merge the batch dimension and the num_choice dimension
        edge_index_orig, edge_type_orig = inputs[-2:]
        _inputs = (
            [x.view(x.size(0) * x.size(1), *x.size()[2:]) for x in inputs[:-6]]
            + [x.view(x.size(0) * x.size(1), *x.size()[2:]) for x in inputs[-6:-2]]
            + [sum(x, []) for x in inputs[-2:]]
        )

        (
            *lm_inputs,
            concept_ids,
            node_type_ids,
            node_scores,
            adj_lengths,
            edge_index,
            edge_type,
        ) = _inputs
        edge_index, edge_type = self.batch_graph(edge_index, edge_type, concept_ids.size(1))
        adj = (edge_index.to(node_type_ids.device), edge_type.to(node_type_ids.device))
        sent_vecs, all_hidden_states = self.encoder(*lm_inputs, layer_id=layer_id)
        logits, attn = self.decoder(
            sent_vecs.to(node_type_ids.device),
            concept_ids,
            node_type_ids,
            node_scores,
            adj_lengths,
            adj,
            emb_data=None,
            cache_output=cache_output,
        )
        logits = logits.view(bs, nc)
        if not detail:
            return logits, attn
        else:
            return (
                logits,
                attn,
                concept_ids.view(bs, nc, -1),
                node_type_ids.view(bs, nc, -1),
                edge_index_orig,
                edge_type_orig,
            )

    def batch_graph(self, edge_index_init, edge_type_init, n_nodes):
        n_examples = len(edge_index_init)
        edge_index = [edge_index_init[_i_] + _i_ * n_nodes for _i_ in range(n_examples)]
        edge_index = torch.cat(edge_index, dim=1)
        edge_type = torch.cat(edge_type_init, dim=0)
        return edge_index, edge_type


def make_one_hot(labels, C):
    """
    Converts an integer label torch.autograd.Variable to a one-hot Variable.
    labels : torch.autograd.Variable of torch.cuda.LongTensor
        (N, ), where N is batch size.
        Each value is an integer representing correct classification.
    C : integer.
        number of classes in labels.
    Returns : torch.autograd.Variable of torch.cuda.FloatTensor
        N x C, where C is class number. One-hot encoded.
    """
    labels = labels.unsqueeze(1)
    one_hot = torch.FloatTensor(labels.size(0), C).zero_().to(labels.device)
    target = one_hot.scatter_(1, labels.data, 1)
    target = Variable(target)
    return target


class GATConvE(MessagePassing):
    """
    Args:
        emb_dim (int): dimensionality of GNN hidden states
        n_ntype (int): number of node types (e.g. 4)
        n_etype (int): number of edge relation types (e.g. 38)
    """

    def __init__(self, args, emb_dim, n_ntype, n_etype, edge_encoder, head_count=4, aggr="add"):
        super(GATConvE, self).__init__(aggr=aggr)
        self.args = args

        assert emb_dim % 2 == 0
        self.emb_dim = emb_dim

        self.n_ntype = n_ntype
        self.n_etype = n_etype
        self.edge_encoder = edge_encoder

        # For attention
        self.head_count = head_count
        assert emb_dim % head_count == 0
        self.dim_per_head = emb_dim // head_count
        self.linear_key = nn.Linear(3 * emb_dim, head_count * self.dim_per_head)
        self.linear_msg = nn.Linear(3 * emb_dim, head_count * self.dim_per_head)
        self.linear_query = nn.Linear(2 * emb_dim, head_count * self.dim_per_head)

        self._alpha = None

        # For final MLP
        self.mlp = torch.nn.Sequential(
            torch.nn.Linear(emb_dim, emb_dim),
            torch.nn.BatchNorm1d(emb_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(emb_dim, emb_dim),
        )

    def forward(
        self,
        x,
        edge_index,
        edge_type,
        node_type,
        node_feature_extra,
        return_attention_weights=False,
    ):

        # Prepare edge feature
        edge_vec = make_one_hot(edge_type, self.n_etype + 1)
        self_edge_vec = torch.zeros(x.size(0), self.n_etype + 1).to(edge_vec.device)
        self_edge_vec[:, self.n_etype] = 1

        head_type = node_type[edge_index[0]]
        tail_type = node_type[edge_index[1]]
        head_vec = make_one_hot(head_type, self.n_ntype)
        tail_vec = make_one_hot(tail_type, self.n_ntype)
        headtail_vec = torch.cat([head_vec, tail_vec], dim=1)
        self_head_vec = make_one_hot(node_type, self.n_ntype)
        self_headtail_vec = torch.cat([self_head_vec, self_head_vec], dim=1)

        edge_vec = torch.cat([edge_vec, self_edge_vec], dim=0)
        headtail_vec = torch.cat([headtail_vec, self_headtail_vec], dim=0)
        edge_embeddings = self.edge_encoder(torch.cat([edge_vec, headtail_vec], dim=1))

        # Add self loops to edge_index
        loop_index = torch.arange(0, x.size(0), dtype=torch.long, device=edge_index.device)
        loop_index = loop_index.unsqueeze(0).repeat(2, 1)
        edge_index = torch.cat([edge_index, loop_index], dim=1)

        x = torch.cat([x, node_feature_extra], dim=1)
        x = (x, x)
        aggr_out = self.propagate(edge_index, x=x, edge_attr=edge_embeddings)
        out = self.mlp(aggr_out)

        alpha = self._alpha
        self._alpha = None

        if return_attention_weights:
            assert alpha is not None
            return out, (edge_index, alpha)
        else:
            return out

    def message(self, edge_index, x_i, x_j, edge_attr):

        assert len(edge_attr.size()) == 2
        assert edge_attr.size(1) == self.emb_dim
        assert x_i.size(1) == x_j.size(1) == 2 * self.emb_dim
        assert x_i.size(0) == x_j.size(0) == edge_attr.size(0) == edge_index.size(1)

        key = self.linear_key(torch.cat([x_i, edge_attr], dim=1)).view(-1, self.head_count, self.dim_per_head)
        msg = self.linear_msg(torch.cat([x_j, edge_attr], dim=1)).view(-1, self.head_count, self.dim_per_head)
        query = self.linear_query(x_j).view(-1, self.head_count, self.dim_per_head)

        query = query / math.sqrt(self.dim_per_head)
        scores = (query * key).sum(dim=2)
        src_node_index = edge_index[0]
        alpha = softmax(scores, src_node_index)
        self._alpha = alpha

        # adjust by outgoing degree of src
        E = edge_index.size(1)  # n_edges
        N = int(src_node_index.max()) + 1  # n_nodes
        ones = torch.full((E,), 1.0, dtype=torch.float).to(edge_index.device)
        src_node_edge_count = scatter(ones, src_node_index, dim=0, dim_size=N, reduce="sum")[src_node_index]
        assert len(src_node_edge_count.size()) == 1 and len(src_node_edge_count) == E
        alpha = alpha * src_node_edge_count.unsqueeze(1)
        out = msg * alpha.view(-1, self.head_count, 1)
        return out.view(-1, self.head_count * self.dim_per_head)
